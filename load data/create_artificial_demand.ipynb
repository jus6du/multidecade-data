{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: 2022 Aleksander Grochowicz\n",
    "#\n",
    "# SPDX-License-Identifier: GPL-3.0-or-later\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import holidays\n",
    "from utilities import compute_cdd_hdd_artificial, create_daily_data, create_hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JD278300\\AppData\\Local\\Temp\\ipykernel_6548\\252671962.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  temperatures = pd.read_csv('original_data/europe_temperatures_1980-2020.csv', index_col = [0], infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "temperatures = pd.read_csv('original_data/europe_temperatures_1980-2020.csv', index_col = [0], infer_datetime_format=True)\n",
    "temperatures.drop('IS', axis = 1) # Remove Iceland\n",
    "temperatures.index = pd.to_datetime(temperatures.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regression parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_parameters_days = pd.read_csv('processing/reg_parameters_days_of_week_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_hours = pd.read_csv('processing/reg_parameters_hours_of_week_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_temp = pd.read_csv('processing/reg_parameters_temp_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_trend = pd.read_csv('processing/reg_parameters_trend_2010-2014.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our validation year is 2015, compared to the training data from 2010 to 2014, all weather years that we use will be processed on the premise that they happened in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(temperatures.index.to_series().dt.year.unique())\n",
    "countries = list(temperatures.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Add holidays as previously with the `holidays` package and by adding Christmas week and for some countries Orthodox Christmas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_holidays = {}\n",
    "yrs = years.copy()\n",
    "for c in countries:\n",
    "    if c == 'EL':\n",
    "        list_holidays[c] = holidays.CountryHoliday('GR', years = yrs)\n",
    "    else:\n",
    "        try:\n",
    "            list_holidays[c] = holidays.CountryHoliday(c, years = yrs)\n",
    "        except KeyError:\n",
    "            list_holidays[c] = holidays.HolidayBase() #if no holidays are available, e.g. ME, MK        \n",
    "\n",
    "julian = ['ME', 'MK', 'RS']\n",
    "gregorian = countries.copy()\n",
    "for i in countries:\n",
    "    if i in julian:\n",
    "        gregorian.remove(i)\n",
    "\n",
    "# Add last week of the year as holidays.\n",
    "for y in list(yrs):\n",
    "    for i in gregorian:\n",
    "        list_holidays[i].append(date(y,1,2))\n",
    "        list_holidays[i].append(list(pd.date_range(start = date(y, 12, 24), end = date(y, 12, 31), freq = '1D')))\n",
    "    for i in julian:\n",
    "        list_holidays[i].append(list(pd.date_range(start = date(y, 1, 6), end = date(y, 1, 8), freq = '1D')))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add German holidays before reunification (so include reunification as everything is assumed to be in 2015)\n",
    "overlapping_holidays = ['Neujahrestag', 'Karfreitag', 'Ostermontag', 'Auffahrt', 'Pfingstmontag', 'Weihnachten']\n",
    "for y in range(1980, 1991):\n",
    "    for date, name in sorted(holidays.CH(years = y).items()):\n",
    "        if name in overlapping_holidays:\n",
    "            list_holidays['DE'].append({date: name})\n",
    "    list_holidays['DE'].append(str(y)+'-05-01')\n",
    "    list_holidays['DE'].append(str(y)+'-10-03')\n",
    "    list_holidays['DE'].append(str(y)+'-12-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Slovenian holidays before 1992\n",
    "AT_SI = ['Neujahr', 'Allerheiligen', 'Stefanitag'] #New Year's, All Saints Day, Independence Day on Boxing Day\n",
    "for y in range(1980, 1992):\n",
    "    for date, name in sorted(holidays.AT(years = y).items()):\n",
    "        if name in AT_SI:\n",
    "            list_holidays['SI'].append({date: name})\n",
    "    list_holidays['SI'].append(str(y)+'-02-08') #Preseren Day\n",
    "    list_holidays['SI'].append(str(y)+'-04-27') #Day of uprising against occupation\n",
    "    list_holidays['SI'].append(str(y)+'-05-01') #May 1\n",
    "    list_holidays['SI'].append(str(y)+'-05-02') #May 1 over two days\n",
    "    list_holidays['SI'].append(str(y)+'-06-25') #Statehood Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Bulgarian holidays before 1990\n",
    "RO_BG = ['Paștele', 'Anul Nou', 'Ziua Muncii', 'Crăciunul'] #Orthodox Easter, New Year, First of May, Christmas\n",
    "for y in range(1980, 1990):\n",
    "    for date, name in sorted(holidays.RO(years = y).items()):\n",
    "        if name in RO_BG:\n",
    "            list_holidays['BG'].append({date: name})\n",
    "    list_holidays['BG'].append(str(y)+'-03-03') #Liberation Day\n",
    "    list_holidays['BG'].append(str(y)+'-05-06') #Saint George's Day\n",
    "    list_holidays['BG'].append(str(y)+'-05-24') #Bulgarian Education and Culture and Slavonic Literature Day\n",
    "    list_holidays['BG'].append(str(y)+'-09-06') #Unification Day\n",
    "    list_holidays['BG'].append(str(y)+'-09-22') #independence Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute HDD and CDD for all years (with the threshold at 15.5 degrees Celsius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_daily = temperatures.resample('1D').mean()\n",
    "temperatures_daily['weekday'] = temperatures_daily.index.to_series().dt.dayofweek\n",
    "temperatures_daily['holiday'] = False\n",
    "temp_daily = {}\n",
    "for i in countries:\n",
    "    temp_daily[i] = pd.DataFrame(temperatures_daily[[i, 'weekday', 'holiday']])\n",
    "    temp_daily[i].columns = ['temp', 'weekday', 'holiday']\n",
    "temp_with_holidays = temp_daily.copy()\n",
    "for i in temp_with_holidays.keys():\n",
    "    for j in temp_with_holidays[i].index:\n",
    "        if j in list_holidays[i]:\n",
    "            temp_with_holidays[i].at[j, 'holiday'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_hc = compute_cdd_hdd_artificial(temp_daily, countries, threshold_hdd = 15.5, threshold_cdd = 15.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the artificial demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = reg_parameters_trend.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_demand_daily, days, first_day = create_daily_data(reg_parameters_days, reg_parameters_trend.loc[\"par_trend\"], daily_hc, reg_parameters_temp.T, countries, start = 1980, end= 2021, validation_days=1826)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JD278300\\Documents\\Stage\\Create data\\multidecade-data\\load data\\utilities.py:459: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  0 + artificial[i][j // 24] * weekly_profile[i].iloc[k]\n"
     ]
    }
   ],
   "source": [
    "artificial_demand_hourly = create_hourly_data(artificial_demand_daily, reg_parameters_hours, temperatures, first_day, countries, start = 1980, end = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_demand_ts = pd.concat(artificial_demand_hourly, axis = 1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_demand_ts.to_csv('europe_demand_artificial_1980-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'artificial_demand_ts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m artificial_demand_ts[\u001b[39m'\u001b[39m\u001b[39mFR\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'artificial_demand_ts' is not defined"
     ]
    }
   ],
   "source": [
    "artificial_demand_ts['FR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "75977c85990619d1647f36589d3e4595fb105b474683d763bf223bafd2ba259d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
