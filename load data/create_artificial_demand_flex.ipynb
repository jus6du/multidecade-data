{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: 2022 Aleksander Grochowicz\n",
    "#\n",
    "# SPDX-License-Identifier: GPL-3.0-or-later\n",
    "\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import holidays\n",
    "from utilities import compute_cdd_hdd_artificial, create_daily_data, create_hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JD278300\\AppData\\Local\\Temp\\ipykernel_9228\\819469540.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  index =  pd.date_range(start='2021-01-01', end='2021-12-31 23:00:00', freq='H')\n"
     ]
    }
   ],
   "source": [
    "# .txt files from ERA5 notebook\n",
    "temperatures = pd.read_csv('original_data/temp_moy_Nigeria_2021_2021.txt', header = None)\n",
    "temperatures.columns = ['FR']\n",
    "year = 2021\n",
    "index =  pd.date_range(start='2021-01-01', end='2021-12-31 23:00:00', freq='H')\n",
    "temperatures.index =index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load regression parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'processing/justine_europe_parameters_days_of_week_2010-2014.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reg_parameters_days \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mprocessing/justine_europe_parameters_days_of_week_2010-2014.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index_col \u001b[39m=\u001b[39;49m [\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m reg_parameters_hours \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mprocessing/justine_europe_parameters_hours_of_week_2010-2014.csv\u001b[39m\u001b[39m'\u001b[39m, index_col \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m reg_parameters_temp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mprocessing/justine_europe_parameters_temp_2010-2014.csv\u001b[39m\u001b[39m'\u001b[39m, index_col \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\JD278300\\Documents\\Stage\\pypsa-earth-project\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\JD278300\\Documents\\Stage\\pypsa-earth-project\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\JD278300\\Documents\\Stage\\pypsa-earth-project\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\JD278300\\Documents\\Stage\\pypsa-earth-project\\.conda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\JD278300\\Documents\\Stage\\pypsa-earth-project\\.conda\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'processing/justine_europe_parameters_days_of_week_2010-2014.csv'"
     ]
    }
   ],
   "source": [
    "reg_parameters_days = pd.read_csv('processing/justine_europe_parameters_days_of_week_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_hours = pd.read_csv('processing/justine_europe_parameters_hours_of_week_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_temp = pd.read_csv('processing/justine_europe_parameters_temp_2010-2014.csv', index_col = [0])\n",
    "reg_parameters_trend = pd.read_csv('processing/justine_europe_parameters_trend_2010-2014.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans un premier temps on s'intéresse aux coeffcients de régression pour la France\n",
    "reg_days_FR = reg_parameters_days['FR']\n",
    "reg_hours_FR = reg_parameters_hours['FR']\n",
    "reg_temp_FR = reg_parameters_temp['FR']\n",
    "reg_trend_FR = reg_parameters_trend['FR']\n",
    "\n",
    "# reg_days_FR = reg_parameters_days.mean(axis=1)\n",
    "# reg_hours_FR = reg_parameters_hours.mean(axis=1)\n",
    "# reg_temp_FR = reg_parameters_temp.mean(axis=1)\n",
    "# reg_trend_FR = reg_parameters_trend.mean(axis=1)\n",
    "\n",
    "reg_trend_FR=pd.DataFrame(reg_trend_FR)\n",
    "reg_days_FR=pd.DataFrame(reg_days_FR)\n",
    "reg_hours_FR=pd.DataFrame(reg_hours_FR)\n",
    "reg_temp_FR=pd.DataFrame(reg_temp_FR)\n",
    "\n",
    "reg_trend_FR.columns = ['FR']\n",
    "reg_days_FR.columns = ['FR']\n",
    "reg_hours_FR.columns = ['FR']\n",
    "reg_temp_FR.columns = ['FR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45502.300532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47091.296189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47421.640991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47573.598963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46838.053120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41316.903636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38331.676081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FR\n",
       "0  45502.300532\n",
       "1  47091.296189\n",
       "2  47421.640991\n",
       "3  47573.598963\n",
       "4  46838.053120\n",
       "5  41316.903636\n",
       "6  38331.676081"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_days_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans un premier temps on s'intéresse aux coeffcients de régression pour la France\n",
    "# reg_days_FR = reg_parameters_days['FI']\n",
    "# reg_hours_FR = reg_parameters_hours['FI']\n",
    "# reg_temp_FR = reg_parameters_temp['FI']\n",
    "# reg_trend_FR = reg_parameters_trend['FI']\n",
    "\n",
    "# reg_trend_FR=pd.DataFrame(reg_trend_FR)\n",
    "# reg_days_FR=pd.DataFrame(reg_days_FR)\n",
    "# reg_hours_FR=pd.DataFrame(reg_hours_FR)\n",
    "# reg_temp_FR=pd.DataFrame(reg_temp_FR)\n",
    "\n",
    "# reg_trend_FR.columns = ['KR']\n",
    "# reg_days_FR.columns = ['KR']\n",
    "# reg_hours_FR.columns = ['KR']\n",
    "# reg_temp_FR.columns = ['KR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our validation year is 2015, compared to the training data from 2010 to 2014, all weather years that we use will be processed on the premise that they happened in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(temperatures.index.to_series().dt.year.unique())\n",
    "countries = list(temperatures.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Add holidays as previously with the `holidays` package and by adding Christmas week and for some countries Orthodox Christmas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_holidays = {}\n",
    "yrs = years.copy()\n",
    "for c in countries:\n",
    "    if c == 'EL':\n",
    "        list_holidays[c] = holidays.CountryHoliday('GR', years = yrs)\n",
    "    else:\n",
    "        try:\n",
    "            list_holidays[c] = holidays.CountryHoliday(c, years = yrs)\n",
    "        except KeyError:\n",
    "            list_holidays[c] = holidays.HolidayBase() #if no holidays are available, e.g. ME, MK        \n",
    "\n",
    "# julian = ['ME', 'MK', 'RS']\n",
    "# gregorian = countries.copy()\n",
    "# for i in countries:\n",
    "#     if i in julian:\n",
    "#         gregorian.remove(i)\n",
    "\n",
    "# # Add last wee of the year as holidays.\n",
    "# for y in list(yrs):\n",
    "#     for i in gregorian:\n",
    "#         list_holidays[i].append(date(y,1,2))\n",
    "#         list_holidays[i].append(list(pd.date_range(start = date(y, 12, 24), end = date(y, 12, 31), freq = '1D')))\n",
    "#     for i in julian:\n",
    "#         list_holidays[i].append(list(pd.date_range(start = date(y, 1, 6), end = date(y, 1, 8), freq = '1D')))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add German holidays before reunification (so include reunification as everything is assumed to be in 2015)\n",
    "# overlapping_holidays = ['Neujahrestag', 'Karfreitag', 'Ostermontag', 'Auffahrt', 'Pfingstmontag', 'Weihnachten']\n",
    "# for y in range(1980, 1991):\n",
    "#     for date, name in sorted(holidays.CH(years = y).items()):\n",
    "#         if name in overlapping_holidays:\n",
    "#             list_holidays['DE'].append({date: name})\n",
    "#     list_holidays['DE'].append(str(y)+'-05-01')\n",
    "#     list_holidays['DE'].append(str(y)+'-10-03')\n",
    "#     list_holidays['DE'].append(str(y)+'-12-26')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add Slovenian holidays before 1992\n",
    "# AT_SI = ['Neujahr', 'Allerheiligen', 'Stefanitag'] #New Year's, All Saints Day, Independence Day on Boxing Day\n",
    "# for y in range(1980, 1992):\n",
    "#     for date, name in sorted(holidays.AT(years = y).items()):\n",
    "#         if name in AT_SI:\n",
    "#             list_holidays['SI'].append({date: name})\n",
    "#     list_holidays['SI'].append(str(y)+'-02-08') #Preseren Day\n",
    "#     list_holidays['SI'].append(str(y)+'-04-27') #Day of uprising against occupation\n",
    "#     list_holidays['SI'].append(str(y)+'-05-01') #May 1\n",
    "#     list_holidays['SI'].append(str(y)+'-05-02') #May 1 over two days\n",
    "#     list_holidays['SI'].append(str(y)+'-06-25') #Statehood Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add Bulgarian holidays before 1990\n",
    "# RO_BG = ['Paștele', 'Anul Nou', 'Ziua Muncii', 'Crăciunul'] #Orthodox Easter, New Year, First of May, Christmas\n",
    "# for y in range(1980, 1990):\n",
    "#     for date, name in sorted(holidays.RO(years = y).items()):\n",
    "#         if name in RO_BG:\n",
    "#             list_holidays['BG'].append({date: name})\n",
    "#     list_holidays['BG'].append(str(y)+'-03-03') #Liberation Day\n",
    "#     list_holidays['BG'].append(str(y)+'-05-06') #Saint George's Day\n",
    "#     list_holidays['BG'].append(str(y)+'-05-24') #Bulgarian Education and Culture and Slavonic Literature Day\n",
    "#     list_holidays['BG'].append(str(y)+'-09-06') #Unification Day\n",
    "#     list_holidays['BG'].append(str(y)+'-09-22') #independence Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute HDD and CDD for all years (with the threshold at 15.5 degrees Celsius)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_daily = temperatures.resample('1D').mean()\n",
    "temperatures_daily['weekday'] = temperatures_daily.index.to_series().dt.dayofweek\n",
    "temperatures_daily['holiday'] = False\n",
    "temp_daily = {}\n",
    "for i in countries:\n",
    "    temp_daily[i] = pd.DataFrame(temperatures_daily[[i, 'weekday', 'holiday']])\n",
    "    temp_daily[i].columns = ['temp', 'weekday', 'holiday']\n",
    "temp_with_holidays = temp_daily.copy()\n",
    "for i in temp_with_holidays.keys():\n",
    "    for j in temp_with_holidays[i].index:\n",
    "        if j in list_holidays[i]:\n",
    "            temp_with_holidays[i].at[j, 'holiday'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_hc = compute_cdd_hdd_artificial(temp_daily, countries, threshold_hdd = 15.5, threshold_cdd = 15.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FR':             heating  weekday  holiday    cooling\n",
       " 2021-01-01      0.0        4     True  10.955052\n",
       " 2021-01-02      0.0        5    False  11.407763\n",
       " 2021-01-03      0.0        6    False  11.709286\n",
       " 2021-01-04      0.0        0    False  11.996281\n",
       " 2021-01-05      0.0        1    False  12.315797\n",
       " ...             ...      ...      ...        ...\n",
       " 2021-12-27      0.0        0    False  10.467301\n",
       " 2021-12-28      0.0        1    False   9.519262\n",
       " 2021-12-29      0.0        2    False   9.128913\n",
       " 2021-12-30      0.0        3    False   9.159091\n",
       " 2021-12-31      0.0        4    False   9.949555\n",
       " \n",
       " [365 rows x 4 columns]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the artificial demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = list(temperatures.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptation pour année incomplète comme RTE\n",
    "import calendar\n",
    "import numpy as np\n",
    "def create_daily_data(\n",
    "    daily_profile,\n",
    "    trend,\n",
    "    input_data,\n",
    "    temp_par,\n",
    "    place,\n",
    "    start,\n",
    "    end,\n",
    "    validation_days=0,\n",
    "):\n",
    "    \"\"\"Create artificial data based on two regressions from before, one on the weekly load profile and one on the regression on daily values. Also outputs number of days for\\\n",
    "    validation purposes in subsequent period.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    daily_profile -- regression on daily temperature/demand values\n",
    "    trend -- whether to include trend parameters\n",
    "    input_data -- temperature data to be used as input\n",
    "    temp_par -- temperature parameters from regression\n",
    "    place -- list of keys of data \n",
    "    [start, end) -- time period to be studied \n",
    "    validation_days -- number of days to move trend for validation runs\n",
    "    \"\"\"\n",
    "    artificial_daily = {}\n",
    "    first_day = []\n",
    "    first_day = int(input_data[place[0]].iloc[0][\"weekday\"])\n",
    "    days = 0\n",
    "    for year in range(start, end):\n",
    "        if calendar.isleap(year) == True:\n",
    "            days += 366\n",
    "        else:\n",
    "            days += 365\n",
    "    for i in place:\n",
    "       \n",
    "        artificial_daily[i] = np.zeros(days)\n",
    "        for j in range(days):\n",
    "            k = (j + first_day) % 7\n",
    "            if input_data[i][\"holiday\"].iloc[j] == 1:\n",
    "                artificial_daily[i][j] = (\n",
    "                    # trend.loc[i] * (validation_days + j)\n",
    "                    daily_profile[i].iloc[6]\n",
    "                    + input_data[i].iloc[j][\"heating\"] * temp_par.loc[i][\"par_heating\"]\n",
    "                    + input_data[i].iloc[j][\"cooling\"] * temp_par.loc[i][\"par_cooling\"]\n",
    "                )\n",
    "            else:\n",
    "                artificial_daily[i][j] = (\n",
    "                    # trend.loc[i] * (validation_days + j)\n",
    "                    daily_profile[i].iloc[k]\n",
    "                    + input_data[i].iloc[j][\"heating\"] * temp_par.loc[i][\"par_heating\"]\n",
    "                    + input_data[i].iloc[j][\"cooling\"] * temp_par.loc[i][\"par_cooling\"]\n",
    "                )\n",
    "        artificial_daily[i] = pd.Series(artificial_daily[i], index=input_data[i].index)\n",
    "    return artificial_daily, days, first_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>par_trend</th>\n",
       "      <td>-1.376686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FR\n",
       "par_trend -1.376686"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_trend_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_demand_daily, days, first_day = create_daily_data(reg_parameters_days, reg_parameters_trend.loc[\"par_trend\"], daily_hc, reg_parameters_temp.T, countries, start = 1980, end= 2021, validation_days=1826)\n",
    "artificial_demand_daily, days, first_day = create_daily_data(reg_days_FR, pd.DataFrame(reg_trend_FR).loc[\"par_trend\"], daily_hc, reg_temp_FR.T, countries, start = 2021, end= 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JD278300\\Documents\\Stage\\Create data\\multidecade-data\\load data\\utilities.py:460: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  0 + artificial[i][j // 24] * weekly_profile[i].iloc[k]\n"
     ]
    }
   ],
   "source": [
    "artificial_demand_hourly = create_hourly_data(artificial_demand_daily, reg_hours_FR, temperatures, first_day, countries, start = 2021, end = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_demand_ts = pd.concat(artificial_demand_hourly, axis = 1).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>37013.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 01:00:00</th>\n",
       "      <td>36403.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 02:00:00</th>\n",
       "      <td>34819.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 03:00:00</th>\n",
       "      <td>33465.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>33580.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00</th>\n",
       "      <td>50656.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00</th>\n",
       "      <td>48582.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00</th>\n",
       "      <td>47156.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00</th>\n",
       "      <td>49747.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 23:00:00</th>\n",
       "      <td>48392.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          FR\n",
       "2021-01-01 00:00:00  37013.6\n",
       "2021-01-01 01:00:00  36403.3\n",
       "2021-01-01 02:00:00  34819.7\n",
       "2021-01-01 03:00:00  33465.2\n",
       "2021-01-01 04:00:00  33580.6\n",
       "...                      ...\n",
       "2021-12-31 19:00:00  50656.2\n",
       "2021-12-31 20:00:00  48582.9\n",
       "2021-12-31 21:00:00  47156.8\n",
       "2021-12-31 22:00:00  49747.2\n",
       "2021-12-31 23:00:00  48392.1\n",
       "\n",
       "[8760 rows x 1 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_demand_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_demand_ts.to_csv(f'NIGERIA_demand_artificial_2021-2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "75977c85990619d1647f36589d3e4595fb105b474683d763bf223bafd2ba259d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
